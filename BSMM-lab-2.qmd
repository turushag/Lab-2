---
title: "BSMM-lab-2"
subtitle: "BSMM 8740 Fall 2023"
author: "Turusha"
date: "September 25, 2023"
format: html
editor: visual
self-contained: true
---

## Setup

Load packages and data:

```{r}
#install.packages("tidyverse")
#install.packages("gt")          
#install.packages("gtExtras")     
#install.packages("DataExplorer")
#install.packages("tidymodels")
#install.packages("gt")
```

```{r}
library(magrittr)    
library(tidyverse)
library(tidymodels)
library(gt)           
library(gtExtras)     
library(DataExplorer)
```

```{r load-pkg-data}

the_tate <- readr::read_delim("data/the-tate-collection.csv", ";", escape_double = FALSE, trim_ws = TRUE)
the_tate_artists <- readr::read_csv("data/the-tate-artists.csv")
```

## Exercises

### Exercise 1

The the_tate dataset has ***3342*** unique artists who worked from ***1545** to **2012** .* The works were acquired between the years ***1823** and **2013*** .

```{r}
glimpse(the_tate_artists)
```

```{r}
#View(the_tate)
#View(the_tate_artists)
```

```{r}
glimpse(the_tate)

```

```{r}
summary(the_tate)
```

```{r}
#summarize function use to find summary of each artist
the_tate %>% dplyr::group_by(the_tate$artistId) %>% 
dplyr::summarize(N=n(),min_yearworking= min(the_tate$year,na.rm = TRUE),
max_yearworking= max(the_tate$year,na.rm = TRUE),
min_aquistionyear=min(the_tate$acquisitionYear, na.rm = TRUE),
max_acquisitionyear=max(the_tate$year,na.rm = TRUE)  )
```

```{r}

library(dplyr)
# the number of unique artists using select
unique_artists_count <- the_tate %>%
  select(artistId) %>%
  distinct() %>%
  nrow()
unique_artists_count
```

```{r}
# the range of years artists worked
min_year_worked <- min(the_tate$year,na.rm = TRUE)
max_year_worked <- max(the_tate$year,na.rm = TRUE)

# the range of acquisition years
min_acquisition_year <- min(the_tate$acquisitionYear, na.rm = TRUE)
max_acquisition_year <- max(the_tate$acquisitionYear, na.rm = TRUE)

cat (min_year_worked, "to", max_year_worked, ".\n")
```

```{r}
cat( min_acquisition_year, "and", max_acquisition_year, ".\n")

```

```{r}
DataExplorer::introduce(the_tate)

```

```{r}
DataExplorer::introduce(the_tate_artists)

```

```{r}
DataExplorer::plot_missing(the_tate)

```

```{r}
DataExplorer::plot_missing(the_tate_artists)

```

### Exercise 2

How number of works with missing dates is ***5397*** **\
**The number of artists whose works have missing dates is ***462***.

It would require resolving missing year data for only **11** artists resolve at least 50% of the missing data.

The missing year data likely to be classified as ***Missing At Random\
(MAR)***

```{r}
#missing date
missing_dates <- sum(is.na(the_tate$year))
print(missing_dates)
```

The number of artists whose works have missing dates is ***461***.

```{r}
the_tate|>dplyr::filter(is.na(year))|>dplyr::distinct(artistId)

```

```{r}
artists_with_missing_dates <- the_tate %>%
  filter(is.na(year)) %>%
  distinct(artistId) %>%
  nrow()

artists_with_missing_dates
```

```{r}
# the number of works missing years for each artist
artist_missing_year_counts <- the_tate|>dplyr::filter(is.na(year)) %>% 
  group_by(artistId) %>%
  summarise(missing_years = sum(is.na(year))) %>%
  arrange(desc(missing_years)) %>%
  as_tibble()

# Number of artists have works with missing years
artists_with_missing_years <- nrow(artist_missing_year_counts)
artists_with_missing_years
```

It would require resolving missing year data for only **11** artists resolve at least 50% of the missing data.

```{r}
# the percent of total missing data for each artist
artist_missing_year_counts <- artist_missing_year_counts %>%
  mutate(percentage = (missing_years / missing_dates) * 100)

# the cumulative percent of missing data
artist_missing_year_counts <- artist_missing_year_counts %>%
  mutate(cumulative_percentage = cumsum(percentage))

```

```{r}
# the smallest number of artists needed to resolve at least 50% of the missing year data
artists_to_resolve_50_percent <- min(which(artist_missing_year_counts$cumulative_percentage >= 50))

artists_to_resolve_50_percent

```

### Exercise 3

The artist with the most works in the Tate collection is ***Turner, Joseph Mallord William with ID 558***

The artist with the tenth-most works in the Tate collection is ***Warhol, Andy with ID 2121***

```{r}


# Group the data by artist and count the number of works for each artist
artist_work_counts <- the_tate %>%
  group_by(artist) %>%
  summarize(title = n()) %>%
  arrange(desc(title))

# Display the top 10 artists by the number of works
top_10_artists <- artist_work_counts %>%
  slice_head(n = 10)

the_tate %>% dplyr::filter(artistId %in% c(558,2121)) %>% dplyr::select(artistId,artist) %>% distinct(artistId,artist) 



```

```{r}
# Print the table for the top 10 artists
print(top_10_artists)
```

### Exercise 4

The artist with the greatest number of works in the Tate collection represent **56.92**% of the total number of works

```{r}

# the percentage of the total collection for each artist
total_works <- nrow(the_tate)
artist_work_counts <- artist_work_counts %>%
  mutate(percentage = (title / total_works) * 100)

# the table using gt
table <- artist_work_counts %>%
  gt() %>%
  fmt_percent(
    columns = percentage,
    decimals = 2
  ) %>%
  tab_header(title = "Top Artists by Number of Works and Percentage of Collection") %>%

# Print the formatted table
print(table)
```

### Exercise 5

There are ***23705*** duplicate artist-title pairs

```{r}
total_rows <- total_works

# only the columns for artist and title, then count distinct pairs
distinct_artist_title_pair <- the_tate %>% select(artist,title) %>% distinct()

# Count of distinct artist-title pairs
distinct_count <- nrow(distinct_artist_title_pair)

total_rows
```

```{r}
distinct_count

```

```{r}
# Count the number of duplicated artist-title pairs
duplicated_count <- total_rows - distinct_count
duplicated_count
```

### Exercise 6

The artist with the largest work in the tate collection is **Therrien, Robert.** The artist with the smallest work in the collection is **Mesens, E.L.T.** The smallest work has area **2.37 cm\^2.**

```{r}

#  the area of each artwork and add it as a new column
the_tate <- the_tate %>%
  mutate(area_cm2 = (width * height)/100)

#  remove NA values
selected_artworks <- the_tate %>%
  select(artist, title, area_cm2) %>%
  drop_na()  # Remove rows with NA values

#works by area
ordered_artworks <- selected_artworks %>%
  arrange(area_cm2)

# the largest artwork 
largest_artwork <- ordered_artworks %>%
  slice_tail(n = 1)

# the smallest artwork 
smallest_artwork <- ordered_artworks %>%
  slice_head(n = 1)

# Print the largest and smallest artworks

print(largest_artwork)

```

```{r}

print(smallest_artwork)

```

### Exercise 7

```{r}
# Load the required libraries
library(dplyr)



# Left join the tables and group the result by gender
gender_grouped<- the_tate %>%
  left_join(the_tate_artists, by = join_by(artistId == id)) %>%  filter(!is.na(gender)) %>% group_by(gender) 


```

```{r}
# resulting table
gender_grouped
```

### Exercise 8

The annual return in the SPX price in 2020 was **-13.98 (almost 14)** %.

The corresponding price volatility was **34.70**%.

```{r}
library(readr)
dataofstock <- read_csv("data/SPX_HistoricalData_1692322132002.csv")
```

```{r}
#View(dataofstock)
```

```{r}
# Add a column for the year of the transaction
dataofstock <- dataofstock %>%
  mutate(Year = lubridate::year(as.Date(Date, format = "%m/%d/%Y")))

dataofstock <- dataofstock %>%
  rename("close"=`Close/Last`)

dataofstock <- dataofstock %>%
  mutate(rd = log(lead(close) / close))

dataofstock <- dataofstock %>%
  mutate(vard = rd^2)

summary_data <- dataofstock %>%
  group_by(Year) %>%
  summarize(
    Annual_Return = (exp(sum(rd, na.rm = TRUE)) - 1)*100,
    Annual_StdDev = sqrt(sum(vard, na.rm = TRUE))*100,
    .groups = "drop"  # Drop grouping after summary
  )

# Print the summary data
print(summary_data)
```

### Exercise 9

The period volatility was **48.77**%

```{r}
# Install packages for reading the csv file

# Load required libraries
library(dplyr)
library(readr)

# Calculate period return and period volatility
period_return <- prod(1 + summary_data$Annual_Return) - 1
period_volatility <- sqrt(sum(summary_data$Annual_StdDev^2))

# Create summary rows for period return and period volatility
summary_rows <- tibble::tibble(
  Year = as.character("Period"),  # Ensure "Year" is character type
  Annual_Return = period_return,
  Annual_StdDev = period_volatility
)

# Convert the "Year" column in summary_data to character
summary_data <- summary_data |>
  mutate(Year = as.character(Year))

# Combine the summary rows with the summary_data
summary_data <- bind_rows(summary_data, summary_rows)

# Print the summary data
print(summary_data)
```
